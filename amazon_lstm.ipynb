{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LSTM_IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBSHtW6fzAjo",
        "colab_type": "text"
      },
      "source": [
        "# MNIST / LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr4cugH3mZ_X",
        "colab_type": "code",
        "outputId": "87627766-f7bd-474b-98a2-d7b67b557f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Credits: https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
        "# LSTM for sequence classification in the IMDB dataset\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjf2yM5GF4_8",
        "colab_type": "code",
        "outputId": "5646375b-3fc3-4105-c598-44b2636d5602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "#Refer: https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification\n",
        "\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=top_words)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "\r    8192/17464789 [..............................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/datasets/imdb.py:49: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `load_data` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17465344/17464789 [==============================] - 8s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYEE6ts7GAjC",
        "colab_type": "code",
        "outputId": "0d412454-bff2-4d0a-83fc-78047ae336ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(X_train[1]) # representation of text/words in frequency form\n",
        "print(type(X_train[1]))\n",
        "print(len(X_train[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
            "<class 'list'>\n",
            "189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57N6TyKLH-Pc",
        "colab_type": "code",
        "outputId": "daed0207-3367-4693-d790-1eb06f4377aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "# truncate and/or pad input sequences\n",
        "max_review_length = 600\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_train[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 600)\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    1  194 1153  194    2   78  228    5    6\n",
            " 1463 4369    2  134   26    4  715    8  118 1634   14  394   20   13\n",
            "  119  954  189  102    5  207  110 3103   21   14   69  188    8   30\n",
            "   23    7    4  249  126   93    4  114    9 2300 1523    5  647    4\n",
            "  116    9   35    2    4  229    9  340 1322    4  118    9    4  130\n",
            " 4901   19    4 1002    5   89   29  952   46   37    4  455    9   45\n",
            "   43   38 1543 1905  398    4 1649   26    2    5  163   11 3215    2\n",
            "    4 1153    9  194  775    7    2    2  349 2637  148  605    2    2\n",
            "   15  123  125   68    2    2   15  349  165 4362   98    5    4  228\n",
            "    9   43    2 1157   15  299  120    5  120  174   11  220  175  136\n",
            "   50    9 4373  228    2    5    2  656  245 2350    5    4    2  131\n",
            "  152  491   18    2   32    2 1212   14    9    6  371   78   22  625\n",
            "   64 1382    9    8  168  145   23    4 1690   15   16    4 1355    5\n",
            "   28    6   52  154  462   33   89   78  285   16  145   95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CquzlqrOIYGn",
        "colab_type": "code",
        "outputId": "70571de2-8c1a-4f58-8013-3d161cacc3bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# create the model\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 600, 32)           160032    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,333\n",
            "Trainable params: 213,333\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_FT0dPNIeLP",
        "colab_type": "code",
        "outputId": "8cd33490-3970-47db-ebb5-961dc00b1f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "model.fit(X_train, y_train, nb_epoch=2, batch_size=64)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 321s 13ms/step - loss: 0.4870 - acc: 0.7528\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 324s 13ms/step - loss: 0.3096 - acc: 0.8752\n",
            "Accuracy: 86.87%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5KKNg3AgsFr",
        "colab_type": "text"
      },
      "source": [
        "# Amazon / LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrQt465XuT7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import re\n",
        "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "657TjfBQgqoU",
        "colab_type": "code",
        "outputId": "f80607a7-4e6f-4dc0-94fe-f70617f2aee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "\n",
        "!pip install pydrive\n",
        " \n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "  \n",
        "def get_file_names():\n",
        "\n",
        "  # 1. Authenticate and create the PyDrive client.\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  file_list = drive.ListFile({'q': \"'15InUdebAa5obIjKZQWBV_oBKHT3TL0h1' in parents and trashed=false\"}).GetList()\n",
        "  for file1 in file_list:\n",
        "    print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "    \n",
        "    \n",
        "    \n",
        "def get_file_into_colab(file_id,file_name):\n",
        "  \n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  amazon = drive.CreateFile({'id': file_id})\n",
        "  amazon.GetContentFile(file_name)\n",
        "  print(\" Congrats ! Now You can import file into Pandas DataFrame !\")\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.7.11)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.7)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.7)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.0.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.4.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.4.1->google-api-python-client>=1.2->pydrive) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN1fZ5q0gqmA",
        "colab_type": "code",
        "outputId": "871d2fb1-fa8a-4b5c-f157-6c87449c94ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "get_file_names()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "title: Train_so.csv, id: 1QxkbsPaSQUazKHZRfTk1_I7M5a4gSf6T\n",
            "title: train_HAR.csv, id: 1HgwNMzAxgNkYeLbdV-K0wNzMnR4jxY7V\n",
            "title: test_HAR.csv, id: 1-EElNcN1mh-1YbqTZN922HipDSP8HlAS\n",
            "title: total_acc_z_train.txt, id: 1zBX4nWZVsCYcZHZN9CWoGan2MUDfbGAQ\n",
            "title: total_acc_y_train.txt, id: 1OJ0Pg989sYrILuKTZ_egZmm-8IYMC-2H\n",
            "title: total_acc_x_train.txt, id: 1tRjnGtVLoPix04lrIdcHtP9Nr2TwT22w\n",
            "title: body_gyro_z_train.txt, id: 1_JrBhkKTxLI2KJ-bdnOayMMtu0yO9pja\n",
            "title: body_gyro_y_train.txt, id: 1-PiT6oXOhIXtzcj-igd2huqoRoXeZsPw\n",
            "title: body_gyro_x_train.txt, id: 1QiLmTuudrNNx5gOXP2gXB2QCZKE-lbSq\n",
            "title: body_acc_z_train.txt, id: 1lyaEVLnaDACqh9KIwO_QchhrdzYmup1L\n",
            "title: body_acc_y_train.txt, id: 1Wc57xivtW51vudG9SaQEmSBFTAhnyfvD\n",
            "title: X_train.txt, id: 1KXPlGzbZtUq3Q2qj0XuvWtJggZqDe7HE\n",
            "title: body_acc_x_train.txt, id: 1uJG0yG40OUbdTA7jsgHeigaSoYTrAdwf\n",
            "title: total_acc_z_test.txt, id: 1rMI-tDohravwMoJqbBeZ0Muf1TfZ9kRk\n",
            "title: total_acc_y_test.txt, id: 1lpOYCcT0eWpeh7KOUufHO-6MaBLZObwG\n",
            "title: total_acc_x_test.txt, id: 1jYYPtf1PFvl9iATS0Cb1EcAxSrUKBerQ\n",
            "title: body_gyro_z_test.txt, id: 1PC6ImI99o50J6Xgcg8PIZ_YBKBZNeSwV\n",
            "title: body_gyro_y_test.txt, id: 19swSsvrrqmd81Dc18Wsx6DsPk_oazZbA\n",
            "title: body_gyro_x_test.txt, id: 1TeF9hYvXvd74sYWBPRFfdneGm6m1tyPt\n",
            "title: body_acc_z_test.txt, id: 1zrH0QFmA2LtqwB1E6IrlDUaCL5lBNcIo\n",
            "title: body_acc_y_test.txt, id: 1XDMKz_IZaHK-rzgsDqLPvExUTDI68cWh\n",
            "title: body_acc_x_test.txt, id: 1_l6AISmjdjy1ZD35J345Mke5CEvY2x76\n",
            "title: X_test.txt, id: 1SJKCNzghew0tAxiCGR5YXENY4WGfNwws\n",
            "title: y_train.txt, id: 19ekqFZV6f07bYyb1dWk27FJBHAqC8H7a\n",
            "title: subject_train.txt, id: 1jaI63TncIyJwONk7DicOyg27axk8l1Ri\n",
            "title: y_test.txt, id: 1wdi4HRRWVAnG6o49YdBdKt8QzJkzIWcl\n",
            "title: subject_test.txt, id: 1Oet6JHTw6acxYO-gpADJfFt6PdFeGEM8\n",
            "title: alice.wav, id: 1ZABDMinnBkUpZ6yKm3EzJm_kRIHyY4xt\n",
            "title: alice_cut.wav, id: 1cONb1orycKUUjqwhl1iDx-EM6FITw2l3\n",
            "title: Amazon.csv, id: 1HZ0ICAkv_IjrHHT2hAQtJ58RV61PG2cL\n",
            "title: sample.txt, id: 1aLYmdguyPUKAI_ZZz3rAlhlr3XgPI2uP\n",
            "title: mnist_train.csv, id: 1kyh-A_tBCLkhliKKTqw-Rf2CxY5ihh3m\n",
            "title: Train.csv, id: 16v52cAWv3r1dgGOrlbH45qxALug5dGzv\n",
            "title: Titlemoreweight.db, id: 1S_P2E4DxDAwd15YFMgwlvT3NVlfeYqXS\n",
            "title: tag_counts_dict_dtm.csv, id: 11N9uTIotaNDpmJ4KmjCHN7YSD3VNMvWV\n",
            "title: train_no_dup.db, id: 18tA34r3269sybix_jsrDPnWchaaHXpF7\n",
            "title: Processed.db, id: 1MUAVbg0jinwAGi9zwLJDo1K1wdRXKCFB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A8nr1jagqh0",
        "colab_type": "code",
        "outputId": "d8d71bb9-1c02-4062-b69c-a7801453ad49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_file_into_colab('1HZ0ICAkv_IjrHHT2hAQtJ58RV61PG2cL','Amazon.csv')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Congrats ! Now You can import file into Pandas DataFrame !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XROnCqAKio02",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nypJBSzgqfF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('Amazon.csv')\n",
        "# read csv file into pandas DataFRame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr9uI6uAgqbN",
        "colab_type": "code",
        "outputId": "42a44009-c2e9-4c7f-bf37-98df3b15d2db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               Text\n",
              "0           0  ...  I have bought several of the Vitality canned d...\n",
              "1           1  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2           2  ...  This is a confection that has been around a fe...\n",
              "3           3  ...  If you are looking for the secret ingredient i...\n",
              "4           4  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnU8aYPUgqY1",
        "colab_type": "code",
        "outputId": "57fcad13-f48f-4549-d7a9-a5cd44579830",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 525773 entries, 0 to 525772\n",
            "Data columns (total 11 columns):\n",
            "Unnamed: 0                525773 non-null int64\n",
            "Id                        525773 non-null int64\n",
            "ProductId                 525773 non-null object\n",
            "UserId                    525773 non-null object\n",
            "ProfileName               525773 non-null object\n",
            "HelpfulnessNumerator      525773 non-null int64\n",
            "HelpfulnessDenominator    525773 non-null int64\n",
            "Score                     525773 non-null int64\n",
            "Time                      525773 non-null int64\n",
            "Summary                   525773 non-null object\n",
            "Text                      525773 non-null object\n",
            "dtypes: int64(6), object(5)\n",
            "memory usage: 44.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfIhiBfplkRN",
        "colab_type": "text"
      },
      "source": [
        "## Pre-processing data to represent review as a +ve or -ve review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyWMBL58ljdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# geting first 20k Score values as train data\n",
        "score_train=df.Score[:20000]\n",
        "score_test=df.Score[20000:22000]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deuyVLohljap",
        "colab_type": "code",
        "outputId": "5eec986f-3b86-4a16-d36e-faf5c968f2b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(score_train[:5])\n",
        "score_test[:5]\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    5\n",
            "1    1\n",
            "2    4\n",
            "3    2\n",
            "4    5\n",
            "Name: Score, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000    5\n",
              "20001    5\n",
              "20002    4\n",
              "20003    5\n",
              "20004    5\n",
              "Name: Score, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3H5ZXT0ljYQ",
        "colab_type": "code",
        "outputId": "ae8bbb9a-a498-4d24-ae7f-1e0f8b6649db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# lets create y with binary values -> 1 for Score= 4 & 5 / 0 for Score= 1 & 2\n",
        "\n",
        "y_train=[]\n",
        "\n",
        "for i in tqdm(score_train):\n",
        "  if i <3:\n",
        "    y_train.append(0)\n",
        "  else:\n",
        "    y_train.append(1)\n",
        "\n",
        "\n",
        "y_test=[]\n",
        "\n",
        "for i in tqdm(score_test):\n",
        "  if i <3:\n",
        "    y_test.append(0)\n",
        "  else:\n",
        "    y_test.append(1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20000/20000 [00:00<00:00, 1043865.56it/s]\n",
            "100%|██████████| 2000/2000 [00:00<00:00, 429128.71it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs51VDdGljTM",
        "colab_type": "code",
        "outputId": "c0eb9727-8ffc-4cec-a62a-aef0d7e2fd87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(y_train[:5])\n",
        "y_test[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0, 1, 0, 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 1, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AghrLjXe1le6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# getting only first 20k datapoints only for text feature (column) \n",
        "\n",
        "text_train=df.Text[:20000].values\n",
        "text_test=df.Text[20000:22000].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYNXBc3PVqoc",
        "colab_type": "text"
      },
      "source": [
        "#Function to plot Train & Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3ErFmLzVqEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
        "# https://stackoverflow.com/a/14434334\n",
        "# this function is used to update the plots for each epoch and error\n",
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
        "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
        "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    fig.canvas.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDMpWT_31LQW",
        "colab_type": "text"
      },
      "source": [
        "#Keras Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZldzyE31Kir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "t=Tokenizer(num_words=5000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eziAaYGO1KhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fitting tokenier on train_text data\n",
        "t.fit_on_texts(text_train)\n",
        "# generating sequence for text_train data based on previously trained/fit tokenizer\n",
        "train_sequences=t.texts_to_sequences(text_train)\n",
        "# generating sequence for test_text data based on trained/fit tokenizer on train_text data\n",
        "test_sequences=t.texts_to_sequences(text_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x2-qU1B1Kc4",
        "colab_type": "code",
        "outputId": "0e319b5f-ad39-45ea-f0e5-618db889e3e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(train_sequences[:2])\n",
        "print(\"*\"*50)\n",
        "len(train_sequences)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 17, 125, 315, 7, 1, 572, 81, 54, 199, 3, 17, 115, 28, 39, 5, 30, 7, 29, 170, 1, 38, 540, 51, 26, 4, 2737, 56, 4, 1220, 463, 3, 6, 714, 98, 13, 8, 1617, 3, 90, 9, 38, 98, 56, 149], [38, 346, 2011, 23, 3769, 1782, 823, 1, 823, 79, 258, 188, 990, 3572, 20, 205, 40, 9, 21, 70, 2873, 32, 40, 1, 1527, 3149, 5, 1, 38, 23, 3769]]\n",
            "**************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7asAjvuc1KbC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_val,y_train,y_val=train_test_split(train_sequences,y_train,test_size=0.25)\n",
        "\n",
        "x_test=test_sequences\n",
        "y_test=y_test\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U27TrcX1KXH",
        "colab_type": "code",
        "outputId": "268aa3c8-9e2a-4ac0-d37b-43ccd9c9489c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# truncate and/or pad input sequences so as to make every input/review of length 600\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_review_length = 600\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_review_length)\n",
        "x_val = sequence.pad_sequences(x_val, maxlen=max_review_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_review_length)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15000, 600)\n",
            "(5000, 600)\n",
            "(2000, 600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omGwWU-NEM22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"def best_model(n_hidden,dropout):\n",
        "  \n",
        "  top_words=5000 \n",
        "\n",
        "  # we have changed this cz our frequency representation of words has max value of 5000 (Tokenizer(num_words=5000))\n",
        "\n",
        "  embedding_vecor_length = 32\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(LSTM(n_hidden))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid')) # only one neuron with sigmoid activation, because its binary classification problem\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\"\"\"\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# create the model\n",
        "\n",
        "#top_words = 5000\n",
        "\n",
        "\"\"\"\n",
        "Now notice that, we have increased the number of test datapoints so as to get the vocab size equal to vocab_train size...\n",
        "but its lil bigger i.e 53912, so we will consider top_words=53912 rather than 50959...since 53912 > 50959\n",
        "\"\"\"\n",
        "\n",
        "top_words=5000 \n",
        "\n",
        "# we have changed this cz our frequency representation of words has max value of 5000 (Tokenizer(num_words=5000))\n",
        "\n",
        "embedding_vecor_length = 32\n",
        "\n",
        "\n",
        "\n",
        "def best_model(n_hidden,dropout):\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "  #model.add(BatchNormalization())\n",
        "\n",
        "  model.add(LSTM(n_hidden))\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(BatchNormalization())\n",
        "  \"\"\"\n",
        "  model.add(LSTM(20))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(BatchNormalization())\"\"\"\n",
        "\n",
        "  model.add(Dense(50, activation='relu')) \n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Dense(1, activation='sigmoid')) # only one neuron with sigmoid activation, because its binary classification problem\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  #print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nGyCp-tFar_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout=[0.2,0.3,0.5]\n",
        "n_hidden=[20,30,50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYBHIHKSEMwf",
        "colab_type": "code",
        "outputId": "967a6143-65af-489d-dcc0-d2ada4ac2051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "model=KerasClassifier(build_fn=best_model)\n",
        "param_grid=dict(dropout=dropout,n_hidden=n_hidden)\n",
        "\n",
        "print(param_grid)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dropout': [0.2, 0.3, 0.5], 'n_hidden': [20, 30, 50]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O9sZ71aExjN",
        "colab_type": "code",
        "outputId": "4d441e24-aa6f-4391-8fbb-e51a48ae43aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "grid=GridSearchCV(estimator=model,param_grid=param_grid)\n",
        "grid_result=grid.fit(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 131s 13ms/step - loss: 0.4820 - acc: 0.7830\n",
            "5000/5000 [==============================] - 11s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 131s 13ms/step - loss: 0.4982 - acc: 0.7675\n",
            "5000/5000 [==============================] - 11s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 132s 13ms/step - loss: 0.4826 - acc: 0.7702\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 130s 13ms/step - loss: 0.4816 - acc: 0.7780\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 132s 13ms/step - loss: 0.4837 - acc: 0.7792\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 134s 13ms/step - loss: 0.4814 - acc: 0.7757\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 129s 13ms/step - loss: 0.5067 - acc: 0.7657\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 127s 13ms/step - loss: 0.4737 - acc: 0.7733\n",
            "5000/5000 [==============================] - 11s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 129s 13ms/step - loss: 0.4733 - acc: 0.7839\n",
            "5000/5000 [==============================] - 11s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 129s 13ms/step - loss: 0.4881 - acc: 0.7723\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 129s 13ms/step - loss: 0.4867 - acc: 0.7767\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 130s 13ms/step - loss: 0.4864 - acc: 0.7765\n",
            "5000/5000 [==============================] - 11s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 128s 13ms/step - loss: 0.4784 - acc: 0.7724\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 128s 13ms/step - loss: 0.4846 - acc: 0.7727\n",
            "5000/5000 [==============================] - 12s 2ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 128s 13ms/step - loss: 0.4951 - acc: 0.7633\n",
            "5000/5000 [==============================] - 13s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 131s 13ms/step - loss: 0.4805 - acc: 0.7748\n",
            "5000/5000 [==============================] - 14s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 131s 13ms/step - loss: 0.4989 - acc: 0.7707\n",
            "5000/5000 [==============================] - 13s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 131s 13ms/step - loss: 0.4958 - acc: 0.7712\n",
            "5000/5000 [==============================] - 13s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 130s 13ms/step - loss: 0.4830 - acc: 0.7745\n",
            "5000/5000 [==============================] - 13s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 131s 13ms/step - loss: 0.4812 - acc: 0.7711\n",
            "5000/5000 [==============================] - 13s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 137s 14ms/step - loss: 0.4839 - acc: 0.7708\n",
            "5000/5000 [==============================] - 13s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 134s 13ms/step - loss: 0.4745 - acc: 0.7792\n",
            "5000/5000 [==============================] - 14s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 134s 13ms/step - loss: 0.4904 - acc: 0.7708\n",
            "5000/5000 [==============================] - 14s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 132s 13ms/step - loss: 0.5061 - acc: 0.7627\n",
            "5000/5000 [==============================] - 14s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 130s 13ms/step - loss: 0.4866 - acc: 0.7771\n",
            "5000/5000 [==============================] - 13s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 131s 13ms/step - loss: 0.4974 - acc: 0.7630\n",
            "5000/5000 [==============================] - 14s 3ms/step\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 137s 14ms/step - loss: 0.5252 - acc: 0.7657\n",
            "5000/5000 [==============================] - 14s 3ms/step\n",
            "Epoch 1/1\n",
            "15000/15000 [==============================] - 195s 13ms/step - loss: 0.4347 - acc: 0.8015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EVPo4gSMTdF",
        "colab_type": "code",
        "outputId": "df131f6a-60f1-46dd-e94a-d38e2d065200",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grid_result.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dropout': 0.5, 'n_hidden': 20}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UPMQItdnND0",
        "colab_type": "text"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0To_tURKExfr",
        "colab_type": "code",
        "outputId": "176ad3cd-4577-444c-bafc-ac1001bf90dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# create the model\n",
        "\n",
        "#top_words = 5000\n",
        "\n",
        "\"\"\"\n",
        "Now notice that, we have increased the number of test datapoints so as to get the vocab size equal to vocab_train size...\n",
        "but its lil bigger i.e 53912, so we will consider top_words=53912 rather than 50959...since 53912 > 50959\n",
        "\"\"\"\n",
        "\n",
        "top_words=5000 \n",
        "\n",
        "# we have changed this cz our frequency representation of words has max value of 5000 (Tokenizer(num_words=5000))\n",
        "\n",
        "embedding_vecor_length = 32\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(20))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\"\"\"\n",
        "model.add(LSTM(20))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\"\"\"\n",
        "\n",
        "model.add(Dense(50, activation='relu')) \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid')) # only one neuron with sigmoid activation, because its binary classification problem\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_11 (Embedding)     (None, 600, 32)           160032    \n",
            "_________________________________________________________________\n",
            "lstm_14 (LSTM)               (None, 20)                4240      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 20)                80        \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 50)                1050      \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 165,653\n",
            "Trainable params: 165,513\n",
            "Non-trainable params: 140\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCmAK0EjIkj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to make sure there is no any class imbalance \n",
        "# by this we are balancing the class (like what we do in LR i.e class_weight='balanced')\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9jEcdURIke8",
        "colab_type": "code",
        "outputId": "1bd91e83-22c9-4836-c4db-843414daa526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "history=model.fit(x_train,y_train,nb_epoch=5,batch_size=128,class_weight=class_weights,validation_data=(x_val,y_val))\n",
        "#it returns all info collected during training i.e history\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "15000/15000 [==============================] - 65s 4ms/step - loss: 0.5757 - acc: 0.7206 - val_loss: 0.3753 - val_acc: 0.8576\n",
            "Epoch 2/5\n",
            "15000/15000 [==============================] - 62s 4ms/step - loss: 0.3015 - acc: 0.8939 - val_loss: 0.2651 - val_acc: 0.8986\n",
            "Epoch 3/5\n",
            "15000/15000 [==============================] - 63s 4ms/step - loss: 0.1888 - acc: 0.9354 - val_loss: 0.3020 - val_acc: 0.8918\n",
            "Epoch 4/5\n",
            "15000/15000 [==============================] - 63s 4ms/step - loss: 0.1443 - acc: 0.9508 - val_loss: 0.2748 - val_acc: 0.9050\n",
            "Epoch 5/5\n",
            "15000/15000 [==============================] - 64s 4ms/step - loss: 0.1140 - acc: 0.9620 - val_loss: 0.3063 - val_acc: 0.9062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcUyvRRHIkdQ",
        "colab_type": "code",
        "outputId": "2e5d6c25-23db-42d6-c8b7-59784648eb3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "print(\"Loss Score: %.2f%%\" % (scores[0]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.90%\n",
            "Loss Score: 0.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUL_JM0OArPJ",
        "colab_type": "text"
      },
      "source": [
        "1. Before introducing BN layer...val loss was 12 in first epoch and acc score was ~15%.\n",
        "2. Now with BN layer, model has improved.\n",
        "3. Also loss difference betwenn train & validation data has improved from previously built models which indicates we are succesfully able to avoid model overfitting to some extent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A28pkSZm1KJ3",
        "colab_type": "code",
        "outputId": "fcca5353-f6fe-4d8c-c935-524897f1ec3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "\n",
        "\"\"\"score = model_drop.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test score:', score[0]) \n",
        "print('Test accuracy:', score[1])\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "fig,ax = plt.subplots(1,1)\n",
        "ax.set_xlabel('epoch') ; \n",
        "ax.set_ylabel('Categorical Crossentropy Loss')\n",
        "\n",
        "# list of epoch numbers\n",
        "x = list(range(1,5+1))\n",
        "\n",
        "# print(history.history.keys())\n",
        "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
        "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
        "\n",
        "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
        "# val_loss : validation loss\n",
        "# val_acc : validation accuracy\n",
        "\n",
        "# loss : training loss\n",
        "# acc : train accuracy\n",
        "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
        "\n",
        "vy = history.history['val_loss']\n",
        "ty = history.history['loss']\n",
        "plt_dynamic(x, vy, ty, ax)\n",
        "#plt.plot(x,ty)\n",
        "#plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support. ' +\n",
              "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option);\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>');\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        event.shiftKey = false;\n",
              "        // Send a \"J\" for go to next cell\n",
              "        event.which = 74;\n",
              "        event.keyCode = 74;\n",
              "        manager.command_mode();\n",
              "        manager.handle_keydown(event);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='e57f84ae-bafc-4ecb-94d4-55598bf9c0a7'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIgU87KxV0fs",
        "colab_type": "text"
      },
      "source": [
        "##Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EebmoW091KGE",
        "colab_type": "code",
        "outputId": "938b27e1-e690-4a6b-9668-6a3726259e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# create the model\n",
        "\n",
        "#top_words = 5000\n",
        "\n",
        "\"\"\"\n",
        "Now notice that, we have increased the number of test datapoints so as to get the vocab size equal to vocab_train size...\n",
        "but its lil bigger i.e 53912, so we will consider top_words=53912 rather than 50959...since 53912 > 50959\n",
        "\"\"\"\n",
        "\n",
        "top_words=5000 \n",
        "\n",
        "# we have changed this cz our frequency representation of words has max value of 5000 (Tokenizer(num_words=5000))\n",
        "\n",
        "embedding_vecor_length = 32\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(LSTM(70,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(LSTM(50))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "model.add(LSTM(20))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\"\"\"\n",
        "\n",
        "model.add(Dense(50, activation='relu')) \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid')) # only one neuron with sigmoid activation, because its binary classification problem\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_13 (Embedding)     (None, 600, 32)           160032    \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 600, 32)           128       \n",
            "_________________________________________________________________\n",
            "lstm_17 (LSTM)               (None, 600, 70)           28840     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 600, 70)           0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 600, 70)           280       \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 50)                24200     \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 216,481\n",
            "Trainable params: 216,077\n",
            "Non-trainable params: 404\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nma1WVT1KC9",
        "colab_type": "code",
        "outputId": "e300bb12-6a34-4ccc-c68d-bbe6191df395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "history=model.fit(x_train,y_train,nb_epoch=5,batch_size=128,class_weight=class_weights,validation_data=(x_val,y_val))\n",
        "#it returns all info collected during training i.e history\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "15000/15000 [==============================] - 262s 17ms/step - loss: 0.6259 - acc: 0.6730 - val_loss: 0.3933 - val_acc: 0.8496\n",
            "Epoch 2/5\n",
            "15000/15000 [==============================] - 261s 17ms/step - loss: 0.3740 - acc: 0.8523 - val_loss: 0.7188 - val_acc: 0.6960\n",
            "Epoch 3/5\n",
            "15000/15000 [==============================] - 263s 18ms/step - loss: 0.2587 - acc: 0.9017 - val_loss: 0.2504 - val_acc: 0.9092\n",
            "Epoch 4/5\n",
            "15000/15000 [==============================] - 262s 17ms/step - loss: 0.1972 - acc: 0.9278 - val_loss: 0.2543 - val_acc: 0.9114\n",
            "Epoch 5/5\n",
            "15000/15000 [==============================] - 262s 17ms/step - loss: 0.1462 - acc: 0.9497 - val_loss: 0.2450 - val_acc: 0.9096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VKJbgzz1KAX",
        "colab_type": "code",
        "outputId": "151c9b1e-83a5-414f-e368-cf170b70287f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "print(\"Loss Score: %.2f%%\" % (scores[0]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 86.35%\n",
            "Loss Score: 0.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e70JyBmlWEr",
        "colab_type": "text"
      },
      "source": [
        "## Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKsTGz6Og2OC",
        "colab_type": "code",
        "outputId": "eaabac3c-83f5-482e-a9a9-19a443dc4a02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "from keras.layers import BatchNormalization, Conv1D, MaxPool1D\n",
        "\n",
        "# create the model\n",
        "\n",
        "#top_words = 5000\n",
        "\n",
        "\"\"\"\n",
        "Now notice that, we have increased the number of test datapoints so as to get the vocab size equal to vocab_train size...\n",
        "but its lil bigger i.e 53912, so we will consider top_words=53912 rather than 50959...since 53912 > 50959\n",
        "\"\"\"\n",
        "\n",
        "top_words=5000 \n",
        "\n",
        "# we have changed this cz our frequency representation of words has max value of 5000 (Tokenizer(num_words=5000))\n",
        "\n",
        "embedding_vecor_length = 32\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(top_words+1, embedding_vecor_length, input_length=max_review_length))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv1D(filters=100,kernel_size=(3)))\n",
        "\n",
        "# model.add(Conv1D(filters=100,kernel_size=(3))) / using more than 1 COnv1D layer seems to be affecting model performance as acc is decreasing and loss is increasing very much\n",
        "#model.add(BatchNormalization())  / was reducing acc and increasing loss\n",
        "#model.add(MaxPool1D()) / not much effective , as performance was remaining almost same\n",
        "\n",
        "\"\"\"model.add(LSTM(70,return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\"\"\"\n",
        "model.add(LSTM(20))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "model.add(LSTM(20))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "\"\"\"\n",
        "\n",
        "model.add(Dense(50, activation='relu')) \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid')) # only one neuron with sigmoid activation, because its binary classification problem\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 600, 32)           160032    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 600, 32)           128       \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 598, 100)          9700      \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 20)                9680      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 20)                80        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 50)                1050      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 50)                200       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 180,921\n",
            "Trainable params: 180,717\n",
            "Non-trainable params: 204\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoloQMhig2LN",
        "colab_type": "code",
        "outputId": "9e90d913-da59-4a78-98fe-a1e5e80729f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "history=model.fit(x_train,y_train,nb_epoch=5,batch_size=128,class_weight=class_weights,validation_data=(x_val,y_val))\n",
        "#it returns all info collected during training i.e history\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "15000/15000 [==============================] - 103s 7ms/step - loss: 0.6079 - acc: 0.6915 - val_loss: 0.3989 - val_acc: 0.8496\n",
            "Epoch 2/5\n",
            "15000/15000 [==============================] - 101s 7ms/step - loss: 0.3964 - acc: 0.8454 - val_loss: 0.3011 - val_acc: 0.8836\n",
            "Epoch 3/5\n",
            "15000/15000 [==============================] - 101s 7ms/step - loss: 0.2689 - acc: 0.9005 - val_loss: 0.2594 - val_acc: 0.8984\n",
            "Epoch 4/5\n",
            "15000/15000 [==============================] - 102s 7ms/step - loss: 0.1897 - acc: 0.9305 - val_loss: 0.2574 - val_acc: 0.9004\n",
            "Epoch 5/5\n",
            "15000/15000 [==============================] - 100s 7ms/step - loss: 0.1246 - acc: 0.9583 - val_loss: 0.2355 - val_acc: 0.9200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "semFs_zmg2Iz",
        "colab_type": "code",
        "outputId": "d848ad3f-7ec9-40c3-ccc7-186404dca40d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "print(\"Loss Score: %.2f%%\" % (scores[0]))\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 87.40%\n",
            "Loss Score: 0.36%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMKWaAjBlrwb",
        "colab_type": "text"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Moo1XLLim4mt",
        "colab_type": "code",
        "outputId": "f5a70b59-5e0b-4729-e66e-0733df11d0dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "table=PrettyTable()\n",
        "\n",
        "table.field_names=['-','Model 1','Model 2','Model 3']\n",
        "\n",
        "table.add_row(['CNN',0,0,1])\n",
        "table.add_row(['LSTM',1,2,2])\n",
        "table.add_row(['Dense',2,2,2])\n",
        "table.add_row(['Accuracy',86.90,86.35,87.40])\n",
        "table.add_row(['Loss',0.42,0.35,0.36])\n",
        "\n",
        "print(table)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+---------+---------+---------+\n",
            "|    -     | Model 1 | Model 2 | Model 3 |\n",
            "+----------+---------+---------+---------+\n",
            "|   CNN    |    0    |    0    |    1    |\n",
            "|   LSTM   |    1    |    2    |    2    |\n",
            "|  Dense   |    2    |    2    |    2    |\n",
            "| Accuracy |   86.9  |  86.35  |   87.4  |\n",
            "|   Loss   |   0.42  |   0.35  |   0.36  |\n",
            "+----------+---------+---------+---------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmfqzbg-lg39",
        "colab_type": "text"
      },
      "source": [
        "1. Changing architecture seems to be quite effective in terms of minimizing loss which we can notice, model is performing **slightly better in case 2 in terms of loss while accuracy is almost same**\n",
        "2. Also **introducing Conv layer reduced loss as well as accuracy has increased slightly to 87.40%.**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS348Qt4liSx",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion:-\n",
        "\n",
        "1. It was observed that, there is a small improvement in model performance when we introduce class_weight='balanced' parameter while training.\n",
        "\n",
        "2. Again, with more data and huge corpus and also more number of epochs would improve model perofrmance.\n",
        "\n",
        "3. But even with 20k datapoints, model is performing well with decent accuracy and loss score\n",
        "\n",
        "4. Also, with increase in number of layers (LSTM) model didn't improved significantly, rather they were almost same.\n",
        "\n",
        "5. And introducing Conv layer has improved model performance to some extent"
      ]
    }
  ]
}